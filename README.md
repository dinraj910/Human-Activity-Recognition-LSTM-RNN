# ğŸƒ Human Activity Recognition â€” Full-Stack Web Application

> Real-time human activity classification using a **Bidirectional LSTM** deep learning model, streaming sensor data from your mobile browser.

![Python](https://img.shields.io/badge/Python-3.11-3776AB?logo=python&logoColor=white)
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.18-FF6F00?logo=tensorflow&logoColor=white)
![React](https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=white)
![Flask](https://img.shields.io/badge/Flask-3.1-000000?logo=flask&logoColor=white)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Model Details](#model-details)
- [Sliding Window & Overlap](#sliding-window--overlap)
- [Tech Stack](#tech-stack)
- [Project Structure](#project-structure)
- [Getting Started](#getting-started)
- [API Reference](#api-reference)
- [Deployment](#deployment)
- [Screenshots](#screenshots)

---

## ğŸ§  Overview

This application classifies **6 human activities** in real time:

| Activity            | MET Value | Description |
|---------------------|-----------|-------------|
| ğŸš¶ WALKING          | 3.5       | Normal pace walking |
| ğŸ§— WALKING_UPSTAIRS | 8.0       | Climbing stairs |
| ğŸƒ WALKING_DOWNSTAIRS| 4.0      | Descending stairs |
| ğŸª‘ SITTING          | 1.3       | Seated position |
| ğŸ§ STANDING         | 1.8       | Upright standing |
| ğŸ›Œ LAYING           | 1.0       | Lying down |

The system uses the **UCI HAR Dataset** accelerometer and gyroscope signals captured at 50 Hz.

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Mobile Browser                        â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚   DeviceMotion API (Accelerometer + Gyroscope)   â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚         Circular Buffer (128 timesteps)           â”‚   â”‚
â”‚  â”‚         50% overlap â†’ shift 64 samples            â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                          â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚  â”‚              React Dashboard                      â”‚   â”‚
â”‚  â”‚  â€¢ Activity Card  â€¢ Sensor Chart  â€¢ Timeline     â”‚   â”‚
â”‚  â”‚  â€¢ Calorie Tracker  â€¢ Session Stats              â”‚   â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚ POST /predict
                           â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flask Backend                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Validate   â”‚â†’ â”‚ Scale data  â”‚â†’ â”‚ LSTM Inference   â”‚  â”‚
â”‚  â”‚ (128 Ã— 6)  â”‚  â”‚ (scaler.pkl)â”‚  â”‚ (har_model.h5)   â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                          â”‚               â”‚
â”‚                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                    â–¼                                     â”‚
â”‚            { activity, confidence }                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”¬ Model Details

### Why LSTM?

Human activities produce **temporal sequences** of sensor data. LSTMs (Long Short-Term Memory networks) excel at learning patterns across time steps â€” they can capture the rhythmic stride pattern of walking vs. the stillness of sitting.

### Architecture

```
Input(128, 6)
  â†’ Bidirectional LSTM(128 units, return_sequences=True)
  â†’ BatchNormalization â†’ Dropout(0.4)
  â†’ Bidirectional LSTM(64 units)
  â†’ BatchNormalization â†’ Dropout(0.4)
  â†’ Dense(64, ReLU) â†’ Dropout(0.3)
  â†’ Dense(6, Softmax) â†’ Output
```

- **Bidirectional**: Processes sequences forwards AND backwards for richer context
- **Stacked**: Two LSTM layers extract hierarchical temporal features
- **Regularisation**: BatchNorm + Dropout prevent overfitting
- **Accuracy**: ~96%+ on UCI HAR test set

### Input Features (per timestep)

| Index | Feature | Source |
|-------|---------|--------|
| 0 | ax | Body Accelerometer X |
| 1 | ay | Body Accelerometer Y |
| 2 | az | Body Accelerometer Z |
| 3 | gx | Body Gyroscope X |
| 4 | gy | Body Gyroscope Y |
| 5 | gz | Body Gyroscope Z |

---

## ğŸ“ Sliding Window & Overlap

```
Sensor Stream:  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’
                |â† 128 samples (Window 1) â†’|
                                |â† 128 samples (Window 2) â†’|
                                                |â† 128 (W3) â†’|
                |â†â”€â”€ 64 shift â”€â”€â†’|
```

- **Window size**: 128 timesteps (~2.56 seconds at 50 Hz)
- **Overlap**: 50% (shift = 64 samples)
- **Why overlap?** Activity transitions often occur mid-window. Overlapping ensures we don't miss transition boundaries and provides smoother predictions.

---

## ğŸ› ï¸ Tech Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| Frontend | React 18 + Vite | SPA framework |
| UI | Bootstrap 5 + Custom CSS | Responsive design |
| Charts | Recharts | Real-time sensor plots |
| Animations | Framer Motion | Smooth transitions |
| Backend | Flask 3.1 | REST API |
| ML | TensorFlow / Keras | LSTM inference |
| Scaling | scikit-learn | StandardScaler |
| Deploy | Docker + Gunicorn | Production serving |

---

## ğŸ“ Project Structure

```
har-activity-recognition/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ app.py                  # Flask application factory
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ predict.py          # POST /predict endpoint
â”‚   â”‚   â””â”€â”€ health.py           # GET /health endpoint
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ model_loader.py     # Singleton model/scaler loader
â”‚   â”‚   â”œâ”€â”€ inference.py        # Full prediction pipeline
â”‚   â”‚   â””â”€â”€ preprocessing.py    # StandardScaler transform
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ har_model.h5        # Trained LSTM model
â”‚   â”‚   â”œâ”€â”€ scaler.pkl          # Fitted StandardScaler
â”‚   â”‚   â””â”€â”€ class_map.json      # Index â†’ label mapping
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ validators.py       # Input shape/range validation
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ActivityCard.jsx     # Current activity hero card
â”‚   â”‚   â”‚   â”œâ”€â”€ SensorChart.jsx      # Real-time sensor graph
â”‚   â”‚   â”‚   â”œâ”€â”€ Timeline.jsx         # Activity change history
â”‚   â”‚   â”‚   â”œâ”€â”€ CalorieTracker.jsx   # Calorie ring + duration bars
â”‚   â”‚   â”‚   â””â”€â”€ SensorPermission.jsx # Permission request flow
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ sensorService.js     # DeviceMotion + simulation
â”‚   â”‚   â”‚   â”œâ”€â”€ bufferService.js     # Circular buffer + windowing
â”‚   â”‚   â”‚   â””â”€â”€ apiService.js        # Fetch calls + throttling
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx        # Main dashboard (state hub)
â”‚   â”‚   â”‚   â””â”€â”€ Landing.jsx          # Landing page
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ calorieUtils.js      # MET values, colours, helpers
â”‚   â”‚   â”œâ”€â”€ App.jsx
â”‚   â”‚   â”œâ”€â”€ main.jsx
â”‚   â”‚   â””â”€â”€ styles.css               # Design system
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## ğŸš€ Getting Started

### Prerequisites

- **Python 3.10+**
- **Node.js 18+**
- **Trained model files** in `backend/model/`:
  - `har_model.h5` (or `best_har_model.h5` renamed)
  - `scaler.pkl`

### 1. Backend Setup

```bash
cd backend

# Create virtual environment
python -m venv venv
source venv/bin/activate   # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Place your model files
# cp /path/to/best_har_model.h5 model/har_model.h5
# cp /path/to/scaler.pkl model/scaler.pkl

# Run development server
python app.py
# â†’ API available at http://localhost:5000
```

### 2. Frontend Setup

```bash
cd frontend

# Install dependencies
npm install

# Start dev server (proxies API to :5000)
npm run dev
# â†’ Dashboard at http://localhost:3000
```

### 3. Using the App

1. Open `http://localhost:3000` on your **mobile browser** for real sensors
2. Or click **"Demo Mode"** on desktop to use simulated data
3. Grant sensor permissions when prompted
4. Watch the dashboard update in real time!

---

## ğŸ“¡ API Reference

### `POST /predict`

Predict human activity from a sensor window.

**Request:**
```json
{
  "sensor_data": [
    [0.25, 9.81, -0.10, 1.2, -0.5, 0.3],
    ...
  ]
}
```
- `sensor_data`: 128 rows Ã— 6 columns (float)

**Response (200):**
```json
{
  "activity": "WALKING",
  "activity_index": 0,
  "confidence": 0.9423,
  "probabilities": {
    "WALKING": 0.9423,
    "WALKING_UPSTAIRS": 0.0312,
    "WALKING_DOWNSTAIRS": 0.0198,
    "SITTING": 0.0034,
    "STANDING": 0.0021,
    "LAYING": 0.0012
  },
  "inference_ms": 23.45
}
```

**Error Response (400):**
```json
{
  "error": "Expected 128 timesteps, got 64."
}
```

### `GET /health`

```json
{
  "status": "healthy",
  "model_loaded": true,
  "scaler_loaded": true,
  "service": "HAR Prediction API",
  "version": "1.0.0"
}
```

---

## ğŸ³ Deployment

### Docker (Recommended)

```bash
# Build and run both services
docker-compose up --build

# Backend: http://localhost:5000
# Frontend: http://localhost:3000
```

### Production Considerations

1. **Single Gunicorn worker** â€” TF models are memory-heavy; use threads, not forks
2. **CORS** â€” Set `CORS_ORIGINS` env var to your frontend domain
3. **HTTPS** â€” Required for DeviceMotion API on most mobile browsers
4. **Model caching** â€” Model loads once at startup via singleton pattern
5. **Rate limiting** â€” Frontend throttles API calls to ~1.5/sec max

---

## ğŸ“Š Performance

| Metric | Target | Actual |
|--------|--------|--------|
| Model Accuracy | >90% | ~96% |
| Inference Time | <100ms | ~25ms |
| API Response | <200ms | ~40ms |
| Sensor Sampling | 50 Hz | 50 Hz |
| Window Latency | ~2.56s | ~1.28s (w/ overlap) |

---

## ğŸ“œ License

This project is built for educational and portfolio purposes using the
[UCI HAR Dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones).

---

<p align="center">
  Built with â¤ï¸ using React Â· Flask Â· TensorFlow Â· LSTM
</p>
