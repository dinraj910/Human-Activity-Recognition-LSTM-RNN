<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=280&section=header&text=Human%20Activity%20Recognition&fontSize=52&fontColor=ffffff&animation=fadeIn&fontAlignY=38&desc=ğŸƒ%20Real-Time%20Deep%20Learning%20â€¢%20LSTM%20â€¢%20Mobile%20Sensors&descAlignY=58&descSize=18" width="100%"/>
</p>

<p align="center">
  <a href="#-quick-start"><img src="https://img.shields.io/badge/Quick_Start-â–¶ï¸-00D4AA?style=for-the-badge" alt="Quick Start"/></a>
  <a href="#-live-demo"><img src="https://img.shields.io/badge/Live_Demo-ğŸ“±-7C3AED?style=for-the-badge" alt="Live Demo"/></a>
  <a href="#-api-reference"><img src="https://img.shields.io/badge/API_Docs-ğŸ“¡-0EA5E9?style=for-the-badge" alt="API Docs"/></a>
  <a href="#-architecture"><img src="https://img.shields.io/badge/Architecture-ğŸ—ï¸-F59E0B?style=for-the-badge" alt="Architecture"/></a>
</p>

<p align="center">
  <img src="https://readme-typing-svg.demolab.com?font=Fira+Code&weight=600&size=22&duration=3000&pause=1000&color=7C3AED&center=true&vCenter=true&multiline=true&repeat=true&width=700&height=80&lines=ğŸ§ +Bidirectional+LSTM+%7C+96%25%2B+Accuracy;ğŸ“±+Real+Phone+Sensors+â†’+Live+Predictions+in+~100ms" alt="Typing SVG" />
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Python-3.12-3776AB?style=for-the-badge&logo=python&logoColor=white" alt="Python"/>
  <img src="https://img.shields.io/badge/TensorFlow-2.18-FF6F00?style=for-the-badge&logo=tensorflow&logoColor=white" alt="TensorFlow"/>
  <img src="https://img.shields.io/badge/React-18-61DAFB?style=for-the-badge&logo=react&logoColor=black" alt="React"/>
  <img src="https://img.shields.io/badge/Flask-3.1-000000?style=for-the-badge&logo=flask&logoColor=white" alt="Flask"/>
  <img src="https://img.shields.io/badge/Vite-6.4-646CFF?style=for-the-badge&logo=vite&logoColor=white" alt="Vite"/>
</p>

<p align="center">
  <img src="https://img.shields.io/badge/Status-Active-00D4AA?style=flat-square" alt="Status"/>
  <img src="https://img.shields.io/badge/License-MIT-7C3AED?style=flat-square" alt="License"/>
  <img src="https://img.shields.io/badge/PRs-Welcome-FF6F61?style=flat-square" alt="PRs Welcome"/>
  <img src="https://img.shields.io/badge/Maintained-Yes-00D4AA?style=flat-square" alt="Maintained"/>
  <img src="https://img.shields.io/badge/Model_Accuracy-96%25+-FF6F00?style=flat-square" alt="Accuracy"/>
</p>

---

<br/>

## ğŸ“Œ Quick Navigation

<p align="center">
  <a href="#-overview">Overview</a> â€¢
  <a href="#-features">Features</a> â€¢
  <a href="#-architecture">Architecture</a> â€¢
  <a href="#-model-deep-dive">Model Deep Dive</a> â€¢
  <a href="#-project-structure">Project Structure</a> â€¢
  <a href="#-quick-start">Quick Start</a> â€¢
  <a href="#-live-demo">Live Demo</a> â€¢
  <a href="#-api-reference">API Reference</a> â€¢
  <a href="#-tech-stack">Tech Stack</a> â€¢
  <a href="#-performance">Performance</a> â€¢
  <a href="#-roadmap">Roadmap</a> â€¢
  <a href="#-contributing">Contributing</a>
</p>

<br/>

---

## ğŸ¯ Overview

<table>
<tr>
<td width="50%">

### ğŸ¤” What is this?

A **production-grade full-stack web application** that classifies **6 human activities in real time** using your phone's accelerometer & gyroscope sensors, powered by a **Bidirectional LSTM** deep learning model trained on the UCI HAR Dataset.

> **Point your phone â†’ Walk around â†’ See predictions live.**

</td>
<td width="50%">

### ğŸ’¡ Why does it matter?

| Problem | Solution |
|---------|----------|
| Activity tracking requires wearables | âœ… Uses built-in phone sensors |
| ML models need desktop to run | âœ… Browser sends data â†’ server predicts |
| No real-time feedback | âœ… ~100ms end-to-end latency |
| Privacy concerns | âœ… Data processed transiently, never stored |

</td>
</tr>
</table>

### ğŸ·ï¸ Activities Recognized

<p align="center">

| ğŸš¶ Walking | ğŸ§— Walking Upstairs | ğŸƒ Walking Downstairs | ğŸª‘ Sitting | ğŸ§ Standing | ğŸ›Œ Laying |
|:---:|:---:|:---:|:---:|:---:|:---:|
| MET 3.5 | MET 8.0 | MET 4.0 | MET 1.3 | MET 1.8 | MET 1.0 |

</p>

<br/>

---

## âœ¨ Features

<table>
<tr>
<td>

| Feature | Status | Description |
|---------|:------:|-------------|
| ğŸ§  **Bidirectional LSTM** | âœ… | Stacked BiLSTM with 96%+ accuracy |
| ğŸ“± **Real Phone Sensors** | âœ… | DeviceMotion API at 50 Hz |
| ğŸ“Š **Live Sensor Charts** | âœ… | Real-time accelerometer & gyroscope waveforms |
| ğŸ¯ **Activity Card** | âœ… | Animated hero card with emoji avatars |
| â±ï¸ **Activity Timeline** | âœ… | Scrollable history with timestamps |
| ğŸ”¥ **Calorie Tracker** | âœ… | MET-based estimation with donut chart |
| ğŸ“ˆ **Session Stats** | âœ… | Predictions count, latency, buffer fill |
| ğŸŒ **REST API** | âœ… | Flask backend with structured logging |
| ğŸ® **Demo Mode** | âœ… | Simulated sensors for desktop testing |
| ğŸ”’ **Privacy First** | âœ… | Zero data retention on server |
| ğŸ“ **Sliding Window** | âœ… | 128 timesteps, 50% overlap |
| ğŸ³ **Docker Support** | âœ… | Full docker-compose orchestration |
| ğŸ“± **Mobile Responsive** | âœ… | Glassmorphic dark theme UI |
| ğŸŒ™ **Dark Mode** | âœ… | Premium dark theme with gradients |

</td>
</tr>
</table>

<br/>

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        ğŸ“± MOBILE BROWSER                         â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚          DeviceMotion API  (Accel + Gyro @ 50Hz)         â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚           Circular Buffer (128 Ã— 6 samples)              â”‚   â”‚
â”‚   â”‚              50% Overlap  â†’  Shift 64 samples            â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â”‚                             â–¼                                    â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”‚
â”‚   â”‚                  âš›ï¸  React Dashboard                      â”‚   â”‚
â”‚   â”‚                                                          â”‚   â”‚
â”‚   â”‚    ActivityCard â”‚ SensorChart â”‚ Timeline â”‚ CalorieTracker â”‚   â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                    POST /predict (JSON)
                     128 Ã— 6 float array
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       ğŸ–¥ï¸  FLASK BACKEND                          â”‚
â”‚                                                                  â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚   â”‚ Validate â”‚ â†’  â”‚ StandardScaleâ”‚ â†’  â”‚  Bidirectional     â”‚    â”‚
â”‚   â”‚ (128 Ã— 6)â”‚    â”‚ (scaler.pkl) â”‚    â”‚  LSTM Inference    â”‚    â”‚
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚  (har_model.h5)    â”‚    â”‚
â”‚                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                                                 â”‚               â”‚
â”‚                          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜               â”‚
â”‚                          â–¼                                      â”‚
â”‚                  { activity: "WALKING",                         â”‚
â”‚                    confidence: 0.94,                            â”‚
â”‚                    inference_ms: 97 }                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

<br/>

---

## ğŸ”¬ Model Deep Dive

<details>
<summary><b>ğŸ§  Click to expand â€” LSTM Architecture, Training, & Sliding Window</b></summary>

<br/>

### Why LSTM?

Human activities produce **temporal sequences** of motion data. A simple classifier can't capture the *rhythmic stride pattern* of walking vs. the *stillness* of sitting. LSTMs process sequences step-by-step, maintaining a memory of prior timesteps â€” ideal for time-series classification.

### Network Architecture

```
Input Shape: (128, 6)
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bidirectional LSTM (128 units) â”‚  â† Processes forwards AND backwards
â”‚  return_sequences = True        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BatchNormalization             â”‚
â”‚  Dropout (0.4)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Bidirectional LSTM (64 units)  â”‚  â† Hierarchical temporal features
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  BatchNormalization             â”‚
â”‚  Dropout (0.4)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense (64, ReLU)               â”‚
â”‚  Dropout (0.3)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
             â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dense (6, Softmax)             â”‚  â†’ Output probabilities
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Input Features (per timestep)

| Index | Feature | Sensor | Unit |
|:-----:|---------|--------|------|
| 0 | `ax` | Body Accelerometer X | m/sÂ² |
| 1 | `ay` | Body Accelerometer Y | m/sÂ² |
| 2 | `az` | Body Accelerometer Z | m/sÂ² |
| 3 | `gx` | Body Gyroscope X | rad/s |
| 4 | `gy` | Body Gyroscope Y | rad/s |
| 5 | `gz` | Body Gyroscope Z | rad/s |

### Sliding Window & Overlap

```
Sensor Stream:  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â†’ time
                |â†â”€â”€â”€ 128 samples (Window 1) â”€â”€â†’|
                               |â†â”€â”€â”€ 128 samples (Window 2) â”€â”€â†’|
                                              |â†â”€â”€â”€ 128 (W3) â”€â”€â†’|
                |â†â”€â”€â”€ 64 shift â”€â”€â”€â†’|
```

| Parameter | Value | Rationale |
|-----------|-------|-----------|
| Window Size | 128 timesteps | ~2.56s at 50 Hz â€” captures full gait cycles |
| Overlap | 50% (shift = 64) | Catches activity transitions mid-window |
| Sampling Rate | 50 Hz | Matches UCI HAR dataset |
| Prediction Interval | ~1.28s | Smooth real-time feel |

### Training Details

| Metric | Value |
|--------|-------|
| Dataset | UCI HAR (10,299 windows) |
| Train / Test Split | 7,352 / 2,947 |
| Optimizer | Adam (lr=0.001) |
| Loss | Categorical Crossentropy |
| Epochs | 50 (with EarlyStopping) |
| Best Accuracy | **~96%+** |

</details>

<br/>

---

## ğŸ“ Project Structure

```
har-activity-recognition/
â”‚
â”œâ”€â”€ ğŸ backend/
â”‚   â”œâ”€â”€ app.py                       # Flask application factory + CORS + logging
â”‚   â”œâ”€â”€ routes/
â”‚   â”‚   â”œâ”€â”€ predict.py               # POST /predict â€” main inference endpoint
â”‚   â”‚   â””â”€â”€ health.py                # GET /health â€” liveness probe
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ model_loader.py          # Singleton pattern: lazy-load model + scaler
â”‚   â”‚   â”œâ”€â”€ inference.py             # Full pipeline: preprocess â†’ predict â†’ decode
â”‚   â”‚   â””â”€â”€ preprocessing.py         # StandardScaler transform (matches training)
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ best_har_model.h5        # Trained Bidirectional LSTM weights
â”‚   â”‚   â”œâ”€â”€ scaler.pkl               # Fitted StandardScaler (joblib)
â”‚   â”‚   â””â”€â”€ class_map.json           # { "0": "WALKING", "1": "WALKING_UPSTAIRS", ... }
â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â””â”€â”€ validators.py            # Input shape, type, NaN, range validation
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ âš›ï¸  frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ components/
â”‚   â”‚   â”‚   â”œâ”€â”€ ActivityCard.jsx      # Hero activity card with emoji avatars
â”‚   â”‚   â”‚   â”œâ”€â”€ SensorChart.jsx       # Real-time Recharts line graph
â”‚   â”‚   â”‚   â”œâ”€â”€ Timeline.jsx          # Scrollable activity history
â”‚   â”‚   â”‚   â”œâ”€â”€ CalorieTracker.jsx    # Donut chart + duration progress bars
â”‚   â”‚   â”‚   â””â”€â”€ SensorPermission.jsx  # Permission flow + demo fallback
â”‚   â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”‚   â”œâ”€â”€ sensorService.js      # DeviceMotion API + simulated 50 Hz stream
â”‚   â”‚   â”‚   â”œâ”€â”€ bufferService.js      # Circular buffer with 50% overlap windowing
â”‚   â”‚   â”‚   â””â”€â”€ apiService.js         # Fetch + throttle + timeout management
â”‚   â”‚   â”œâ”€â”€ pages/
â”‚   â”‚   â”‚   â”œâ”€â”€ Dashboard.jsx         # Main dashboard â€” state hub (useReducer)
â”‚   â”‚   â”‚   â””â”€â”€ Landing.jsx           # Landing page with feature grid
â”‚   â”‚   â”œâ”€â”€ utils/
â”‚   â”‚   â”‚   â””â”€â”€ calorieUtils.js       # MET values, colours, icons, calorie math
â”‚   â”‚   â”œâ”€â”€ App.jsx                   # Router + page transitions
â”‚   â”‚   â”œâ”€â”€ main.jsx                  # Entry point
â”‚   â”‚   â””â”€â”€ styles.css                # Full design system (dark theme + glassmorphism)
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js
â”‚
â”œâ”€â”€ ğŸ“¸ screenshots/                   # 14 high-quality screenshots (desktop + mobile)
â”œâ”€â”€ ğŸ““ notebook/                      # Jupyter training notebook + Python script
â”œâ”€â”€ docker-compose.yml                # Full-stack Docker orchestration
â””â”€â”€ README.md                         # â† You are here! ğŸ˜
```

<br/>

---

## ğŸš€ Quick Start

### ğŸ“‹ Prerequisites

| Requirement | Version | Purpose |
|-------------|---------|---------|
| Python | 3.10+ | Backend runtime |
| Node.js | 18+ | Frontend build |
| pip | Latest | Python packages |
| npm | 9+ | JS packages |

### âš¡ Installation

**1.** Clone the repository
```bash
git clone https://github.com/YOUR_USERNAME/har-activity-recognition.git
cd har-activity-recognition
```

**2.** Set up the Backend
```bash
cd backend

# Create & activate virtual environment
python -m venv venv
source venv/bin/activate          # Linux / macOS
# venv\Scripts\activate           # Windows

# Install dependencies
pip install -r requirements.txt
```

**3.** Set up the Frontend
```bash
cd frontend

# Install dependencies
npm install
```

**4.** Start the application
```bash
# Terminal 1 â€” Backend (port 5000)
cd backend && python app.py

# Terminal 2 â€” Frontend (port 3000)
cd frontend && npm run dev
```

**5.** Open the app
```
ğŸ–¥ï¸  Desktop:  http://localhost:3000  â†’  Click "Demo Mode"
ğŸ“±  Mobile:   Use ngrok for HTTPS (required for sensor access)
```

### ğŸ“± Mobile Access (via ngrok)

The `DeviceMotion` API requires **HTTPS** on mobile browsers. Use [ngrok](https://ngrok.com) to create a secure tunnel:

```bash
# Terminal 3
ngrok http 3000

# Open the https://xxxxx.ngrok-free.app URL on your phone
# Grant sensor access â†’ Walk around â†’ See real-time predictions! ğŸ‰
```

<br/>

---

## ğŸ³ Docker Deployment

```bash
# Build and start both services
docker-compose up --build

# ğŸ–¥ï¸  Frontend:  http://localhost:3000
# âš™ï¸  Backend:   http://localhost:5000
```

### Environment Variables

| Variable | Default | Description |
|----------|---------|-------------|
| `FLASK_DEBUG` | `false` | Enable Flask debug mode |
| `CORS_ORIGINS` | `http://localhost:3000` | Allowed CORS origins |
| `HAR_MODEL_PATH` | `model/best_har_model.h5` | Path to trained model |
| `HAR_SCALER_PATH` | `model/scaler.pkl` | Path to fitted scaler |
| `LAZY_LOAD` | `false` | Lazy-load model (vs. eager) |

<br/>

---

## ğŸ“± Live Demo

### ğŸ–¥ï¸ Desktop Views

<table>
<tr>
<td width="50%" align="center">

**Landing Page â€” Hero Section**

<img src="screenshots/desktop2.png" width="100%" alt="Landing page with gradient title, activity pills, and Open Dashboard button"/>

> *Gradient title, activity pills, and deep learning hero section*

</td>
<td width="50%" align="center">

**Landing Page â€” Feature Grid**

<img src="screenshots/desktop3.png" width="100%" alt="Feature cards: Deep Learning LSTM, Real-Time Sensors, Live Visualisation, Privacy First"/>

> *Feature cards showcasing core capabilities with glassmorphism design*

</td>
</tr>
<tr>
<td colspan="2" align="center">

**Dashboard â€” Sensor Permission Request**

<img src="screenshots/desktop1.png" width="80%" alt="Sensor Access Required dialog with Grant Sensor Access and Demo Mode buttons"/>

> *Clean permission flow with API status indicator and demo mode fallback*

</td>
</tr>
</table>

### ğŸ“± Mobile Views â€” Complete User Journey

> Screenshots captured on a real Android device via **ngrok HTTPS tunnel**, using **actual phone sensors** for live activity recognition.

<table>
<tr>
<td width="33%" align="center">

**â‘  Landing Page**

<img src="screenshots/ph1.jpg" width="100%" alt="Mobile landing page via ngrok"/>

> *Landing page via ngrok â€” deep learning badge, gradient title, activity labels*

</td>
<td width="33%" align="center">

**â‘¡ Feature Cards**

<img src="screenshots/ph3.jpg" width="100%" alt="Mobile feature cards"/>

> *Feature cards â€” LSTM, Real-Time Sensors, Live Visualisation, Privacy First*

</td>
<td width="33%" align="center">

**â‘¢ Sensor Permission**

<img src="screenshots/ph4.jpg" width="100%" alt="Mobile sensor permission request"/>

> *Sensor permission dialog with gradient Grant Access button*

</td>
</tr>
</table>

<table>
<tr>
<td width="33%" align="center">

**â‘£ Permission (Variant)**

<img src="screenshots/ph5.jpg" width="100%" alt="Sensor permission variant view"/>

> *Alternate permission view â€” API online, sensor access pending*

</td>
<td width="33%" align="center">

**â‘¤ Walking Detection**

<img src="screenshots/ph6.jpg" width="100%" alt="Walking detected with 62% confidence"/>

> *ğŸš¶ Walking detected! 62% confidence, 101ms latency, live gyroscope stream*

</td>
<td width="33%" align="center">

**â‘¥ Standing Detection**

<img src="screenshots/ph2.jpg" width="100%" alt="Standing detected with 35% confidence"/>

> *ğŸ§ Standing detected â€” Session stats: 24 predictions, 97ms latency*

</td>
</tr>
</table>

<table>
<tr>
<td width="33%" align="center">

**â‘¦ Sitting Detection**

<img src="screenshots/ph7.jpg" width="100%" alt="Sitting detected with 69% confidence"/>

> *ğŸª‘ Sitting at 69% confidence â€” note the flat gyroscope signal*

</td>
<td width="33%" align="center">

**â‘§ Sitting Accelerometer**

<img src="screenshots/ph8.jpg" width="100%" alt="Sitting with accelerometer data shown"/>

> *Accel view during sitting â€” ~9.8 m/sÂ² on Y-axis (gravity), flat X/Z*

</td>
<td width="33%" align="center">

**â‘¨ Climbing Upstairs**

<img src="screenshots/ph11.jpg" width="100%" alt="Walking upstairs detected"/>

> *ğŸ§— Walking Upstairs! 105 predictions made, 154ms latency, active gyro signal*

</td>
</tr>
</table>

<table>
<tr>
<td width="50%" align="center">

**â‘© Activity Timeline**

<img src="screenshots/ph10.jpg" width="60%" alt="Activity timeline showing chronological activity changes"/>

> *Scrollable timeline â€” Upstairs (96%), Laying, Sitting transitions with timestamps & confidence scores. Calorie tracker shows 15.7 kcal burned.*

</td>
<td width="50%" align="center">

**â‘ª Calorie Tracker**

<img src="screenshots/ph9.jpg" width="60%" alt="Calorie tracker with donut chart and activity breakdown"/>

> *Donut chart (15.5 kcal) with per-activity duration bars â€” Sitting 1m 8s, Upstairs 1m 2s, Walking 26s, Downstairs 25s, Laying 7s. Total session: 3m 11s.*

</td>
</tr>
</table>

<br/>

---

## ğŸ“¡ API Reference

### `POST /predict`

Classify a window of sensor data into one of 6 activities.

**Request:**
```json
{
  "sensor_data": [
    [0.25, 9.81, -0.10, 1.2, -0.5, 0.3],
    [0.28, 9.78, -0.12, 1.1, -0.4, 0.2],
    "... (128 rows Ã— 6 columns)"
  ]
}
```

**Response `200 OK`:**
```json
{
  "activity": "WALKING",
  "activity_index": 0,
  "confidence": 0.9423,
  "probabilities": {
    "WALKING": 0.9423,
    "WALKING_UPSTAIRS": 0.0312,
    "WALKING_DOWNSTAIRS": 0.0198,
    "SITTING": 0.0034,
    "STANDING": 0.0021,
    "LAYING": 0.0012
  },
  "inference_ms": 23.45
}
```

**Error `400 Bad Request`:**
```json
{
  "error": "Expected 128 timesteps, got 64."
}
```

### `GET /health`

```json
{
  "status": "healthy",
  "model_loaded": true,
  "scaler_loaded": true,
  "service": "HAR Prediction API",
  "version": "1.0.0"
}
```

<br/>

---

## ğŸ› ï¸ Tech Stack

<table>
<tr>
<td align="center" width="14%"><b>Layer</b></td>
<td align="center" width="20%"><b>Technology</b></td>
<td align="center" width="66%"><b>Purpose</b></td>
</tr>
<tr>
<td align="center">ğŸ¨ Frontend</td>
<td align="center"><img src="https://img.shields.io/badge/React-18-61DAFB?logo=react&logoColor=black" alt="React"/></td>
<td>Component-based SPA with hooks (useState, useReducer, useEffect, useCallback)</td>
</tr>
<tr>
<td align="center">âš¡ Bundler</td>
<td align="center"><img src="https://img.shields.io/badge/Vite-6.4-646CFF?logo=vite&logoColor=white" alt="Vite"/></td>
<td>Lightning-fast HMR dev server with API proxy configuration</td>
</tr>
<tr>
<td align="center">ğŸ“Š Charts</td>
<td align="center"><img src="https://img.shields.io/badge/Recharts-2.15-FF6384?logo=chart.js&logoColor=white" alt="Recharts"/></td>
<td>Real-time sensor waveform line charts with toggleable accelerometer/gyroscope</td>
</tr>
<tr>
<td align="center">ğŸ­ UI</td>
<td align="center"><img src="https://img.shields.io/badge/Bootstrap-5.3-7952B3?logo=bootstrap&logoColor=white" alt="Bootstrap"/></td>
<td>Responsive grid + custom dark glassmorphism CSS design system</td>
</tr>
<tr>
<td align="center">âœ¨ Animation</td>
<td align="center"><img src="https://img.shields.io/badge/Framer_Motion-12-FF0050?logo=framer&logoColor=white" alt="Framer Motion"/></td>
<td>Spring-based page transitions and component animations</td>
</tr>
<tr>
<td align="center">ğŸ Backend</td>
<td align="center"><img src="https://img.shields.io/badge/Flask-3.1-000000?logo=flask&logoColor=white" alt="Flask"/></td>
<td>Lightweight REST API with blueprints, CORS, structured logging</td>
</tr>
<tr>
<td align="center">ğŸ§  ML</td>
<td align="center"><img src="https://img.shields.io/badge/TensorFlow-2.18-FF6F00?logo=tensorflow&logoColor=white" alt="TensorFlow"/></td>
<td>Bidirectional LSTM model inference (Keras .h5 format)</td>
</tr>
<tr>
<td align="center">ğŸ“ Scaling</td>
<td align="center"><img src="https://img.shields.io/badge/scikit--learn-1.6-F7931E?logo=scikitlearn&logoColor=white" alt="scikit-learn"/></td>
<td>StandardScaler to normalise input features (fitted on training data)</td>
</tr>
<tr>
<td align="center">ğŸ³ Deploy</td>
<td align="center"><img src="https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white" alt="Docker"/></td>
<td>Multi-container orchestration with health checks and volume mounts</td>
</tr>
<tr>
<td align="center">ğŸŒ Tunnel</td>
<td align="center"><img src="https://img.shields.io/badge/ngrok-HTTPS-1F1E37?logo=ngrok&logoColor=white" alt="ngrok"/></td>
<td>HTTPS tunnel for mobile sensor access (DeviceMotion requires HTTPS)</td>
</tr>
</table>

<br/>

---

## âš¡ Performance

<table>
<tr>
<td>

| Metric | Target | Achieved |
|--------|:------:|:--------:|
| ğŸ§  Model Accuracy | >90% | **~96%+** âœ… |
| â±ï¸ Inference Time | <100ms | **~97ms** âœ… |
| ğŸŒ API Response | <200ms | **~105ms** âœ… |
| ğŸ“¡ Sensor Sampling | 50 Hz | **50 Hz** âœ… |
| ğŸªŸ Window Latency | ~2.56s | **~1.28s** âœ… |
| ğŸ“¦ Model Size | <10MB | **3.8 MB** âœ… |
| ğŸ”„ Prediction Rate | ~0.7/s | **~0.8/s** âœ… |

</td>
<td>

| Frontend Metric | Value |
|----------------|:-----:|
| Bundle Size (gzipped) | ~82 KB |
| First Contentful Paint | <1.0s |
| Vite Build Time | ~8s |
| Hot Reload | <100ms |
| Components | 5 |
| Services | 3 |

</td>
</tr>
</table>

<br/>

---

## ğŸ—ºï¸ Roadmap

```mermaid
graph LR
    A[âœ… Phase 1<br/>Core MVP] --> B[âœ… Phase 2<br/>Full Dashboard]
    B --> C[ğŸ”„ Phase 3<br/>Enhancements]
    C --> D[ğŸ”® Phase 4<br/>Future]

    style A fill:#00D4AA,stroke:#00D4AA,color:#000
    style B fill:#00D4AA,stroke:#00D4AA,color:#000
    style C fill:#F59E0B,stroke:#F59E0B,color:#000
    style D fill:#7C3AED,stroke:#7C3AED,color:#fff
```

| Phase | Feature | Status |
|:-----:|---------|:------:|
| 1 | LSTM model training on UCI HAR dataset | âœ… Done |
| 1 | Flask REST API with prediction endpoint | âœ… Done |
| 2 | React dashboard with sensor charts | âœ… Done |
| 2 | Calorie tracker, timeline, session stats | âœ… Done |
| 2 | Mobile sensor integration via DeviceMotion | âœ… Done |
| 2 | Docker deployment | âœ… Done |
| 3 | WebSocket for lower latency streaming | ğŸ”„ Planned |
| 3 | TensorFlow.js for on-device inference | ğŸ”„ Planned |
| 3 | PWA with offline support | ğŸ”„ Planned |
| 4 | Multi-user session comparison | ğŸ”® Future |
| 4 | Exercise routine builder | ğŸ”® Future |
| 4 | Apple Watch / WearOS integration | ğŸ”® Future |

<br/>

---

## ğŸ¤ Contributing

Contributions are welcome! Here's how to get started:

```bash
# 1. Fork the repository
# 2. Create a feature branch
git checkout -b feature/awesome-feature

# 3. Make your changes and commit
git commit -m "feat: add awesome feature"

# 4. Push and create a Pull Request
git push origin feature/awesome-feature
```

### Guidelines

- Follow existing code style and project structure
- Write meaningful commit messages
- Add tests for new features
- Update documentation as needed

<br/>

---

## ğŸ“œ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

<br/>

---

## ğŸ‘¤ Author

<p align="center">
  <img src="https://img.shields.io/badge/GitHub-Profile-181717?style=for-the-badge&logo=github&logoColor=white" alt="GitHub"/>
  <img src="https://img.shields.io/badge/LinkedIn-Connect-0A66C2?style=for-the-badge&logo=linkedin&logoColor=white" alt="LinkedIn"/>
  <img src="https://img.shields.io/badge/Portfolio-Website-7C3AED?style=for-the-badge&logo=googlechrome&logoColor=white" alt="Portfolio"/>
  <img src="https://img.shields.io/badge/Email-Contact-EA4335?style=for-the-badge&logo=gmail&logoColor=white" alt="Email"/>
</p>

### ğŸ“ Skills Demonstrated in This Project

<table>
<tr>
<td width="50%">

**Machine Learning & AI**
- Deep Learning (LSTM, BiLSTM)
- Time-series classification
- Feature engineering & data preprocessing
- Model training, evaluation & deployment
- StandardScaler normalization pipeline

</td>
<td width="50%">

**Full-Stack Development**
- React 18 with hooks (useReducer, useCallback)
- Flask REST API with blueprints
- Real-time data streaming & visualization
- Responsive UI design (mobile-first)
- Docker containerization & deployment

</td>
</tr>
<tr>
<td width="50%">

**Software Engineering**
- Clean architecture (services/routes/utils)
- Singleton design pattern
- Input validation & error handling
- Structured logging
- Environment-based configuration

</td>
<td width="50%">

**Domain Knowledge**
- Signal processing (sliding window, overlap)
- Sensor data (accelerometer, gyroscope)
- Web APIs (DeviceMotion, Permissions)
- MET-based calorie estimation
- Cross-platform mobile compatibility

</td>
</tr>
</table>

<br/>

---

## ğŸ™ Acknowledgments

- [UCI HAR Dataset](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones) â€” Anguita et al., 2013
- [TensorFlow / Keras](https://www.tensorflow.org/) â€” Deep learning framework
- [React](https://react.dev/) â€” Frontend UI library
- [Recharts](https://recharts.org/) â€” Composable chart library
- [Framer Motion](https://www.framer.com/motion/) â€” Animation library
- [capsule-render](https://github.com/kyechan99/capsule-render) â€” Dynamic header images
- [Shields.io](https://shields.io/) â€” Badge generation

<br/>

---

## â­ Show Your Support

If this project helped you learn something new or you found it useful, please consider giving it a **star** â­

It helps others discover the project and motivates continued development!

<p align="center">
  <a href="https://github.com/YOUR_USERNAME/har-activity-recognition">
    <img src="https://img.shields.io/badge/â­_Star_This_Repo-FFD700?style=for-the-badge" alt="Star"/>
  </a>
  <a href="https://github.com/YOUR_USERNAME/har-activity-recognition/fork">
    <img src="https://img.shields.io/badge/ğŸ´_Fork_This_Repo-7C3AED?style=for-the-badge" alt="Fork"/>
  </a>
</p>

<br/>

<p align="center">
  <img src="https://capsule-render.vercel.app/api?type=waving&color=gradient&customColorList=6,11,20&height=120&section=footer&animation=twinkling" width="100%"/>
</p>

<p align="center">
  Built with â¤ï¸ using <b>React Â· Flask Â· TensorFlow Â· LSTM</b>
</p>
