# -*- coding: utf-8 -*-
"""Human_Activity_Recognition_LSTM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Ahjm3vXPUHuDgeI1bjRHhYZHWSBZzQ3H

# **Human Activity Recognition using LSTM**

Objective:
Classify human activities using multivariate accelerometer and gyroscope signals.

Dataset:
UCI HAR Dataset (50Hz sampling, 128 timestep windows, 6 activities)

Model:
Deep LSTM architecture with regularization

Evaluation:
Accuracy, Confusion Matrix, Precision, Recall, F1-score

# Install & Setup
"""

import os
import json

# Create directory
os.makedirs("/root/.kaggle", exist_ok=True)

# Move uploaded kaggle.json to proper folder
!mv kaggle.json /root/.kaggle/

# Set permission
!chmod 600 /root/.kaggle/kaggle.json


!kaggle datasets download -d drsaeedmohsen/ucihar-dataset
!unzip -q ucihar-dataset.zip

!ls
!ls "UCI-HAR-Dataset"

"""# Imports & Setup"""

import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import seaborn as sns

from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, confusion_matrix

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import (
    Input, LSTM, Dense, Dropout,
    BatchNormalization, Bidirectional
)
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint

tf.random.set_seed(42)
np.random.seed(42)

"""# Load Dataset"""

def load_signals(folder_path, prefix):
    signals = []
    signal_types = [
        "body_acc_x_",
        "body_acc_y_",
        "body_acc_z_",
        "body_gyro_x_",
        "body_gyro_y_",
        "body_gyro_z_"
    ]

    for signal in signal_types:
        filename = os.path.join(folder_path, signal + prefix + ".txt")
        data = np.loadtxt(filename)
        signals.append(data)

    return np.transpose(np.array(signals), (1, 2, 0))

# Load training data
X_train = load_signals("UCI-HAR Dataset/train/Inertial Signals", "train")
X_test = load_signals("UCI-HAR Dataset/test/Inertial Signals", "test")

y_train = np.loadtxt("UCI-HAR Dataset/train/y_train.txt").astype(int)
y_test = np.loadtxt("UCI-HAR Dataset/test/y_test.txt").astype(int)

print("X_train shape:", X_train.shape)
print("X_test shape:", X_test.shape)

"""# Class Distribution"""

from collections import Counter
print("Train distribution:", Counter(y_train))

sns.countplot(x=y_train)
plt.title("Class Distribution")
plt.show()

"""# Standardization"""

scaler = StandardScaler()

X_train_reshaped = X_train.reshape(-1, 6)
X_test_reshaped  = X_test.reshape(-1, 6)

scaler.fit(X_train_reshaped)

X_train = scaler.transform(X_train_reshaped).reshape(X_train.shape)
X_test  = scaler.transform(X_test_reshaped).reshape(X_test.shape)

"""# One-Hot Encoding"""

y_train = to_categorical(y_train - 1, 6)
y_test  = to_categorical(y_test - 1, 6)

"""# High-Level Model Architecture

We design a strong but controlled model:

Bidirectional LSTM

Stacked LSTM

BatchNorm

Dropout

Proper regularization
"""

input_layer = Input(shape=(128, 6))

x = Bidirectional(LSTM(128, return_sequences=True))(input_layer)
x = BatchNormalization()(x)
x = Dropout(0.4)(x)

x = Bidirectional(LSTM(64))(x)
x = BatchNormalization()(x)
x = Dropout(0.4)(x)

x = Dense(64, activation='relu')(x)
x = Dropout(0.3)(x)

output = Dense(6, activation='softmax')(x)

model = Model(inputs=input_layer, outputs=output)

model.compile(
    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),
    loss='categorical_crossentropy',
    metrics=['accuracy']
)

model.summary()

"""# Callbacks"""

early_stop = EarlyStopping(
    monitor='val_loss',
    patience=8,
    restore_best_weights=True
)

reduce_lr = ReduceLROnPlateau(
    monitor='val_loss',
    factor=0.5,
    patience=5,
    min_lr=1e-5
)

checkpoint = ModelCheckpoint(
    "best_har_model.h5",
    monitor='val_accuracy',
    save_best_only=True
)

"""# Training"""

history = model.fit(
    X_train,
    y_train,
    epochs=60,
    batch_size=64,
    validation_data=(X_test, y_test),
    callbacks=[early_stop, reduce_lr, checkpoint]
)

"""# Evaluation"""

loss, accuracy = model.evaluate(X_test, y_test)
print("Test Accuracy:", accuracy)

"""# Confusion Matrix"""

y_pred = model.predict(X_test)
y_pred_classes = np.argmax(y_pred, axis=1)
y_true = np.argmax(y_test, axis=1)

cm = confusion_matrix(y_true, y_pred_classes)

plt.figure(figsize=(8,6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title("Confusion Matrix")
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.show()

"""# Classification Report"""

print(classification_report(y_true, y_pred_classes))

"""# Save Final Model"""

model.save("final_har_model.h5")

from google.colab import files
files.download("best_har_model.h5")

import joblib

joblib.dump(scaler, "scaler.pkl")

"""# Load Model + Test with Sample Input"""

import numpy as np
import joblib
import tensorflow as tf
import matplotlib.pyplot as plt

# Load model
model = tf.keras.models.load_model("best_har_model.h5")

# Load scaler
scaler = joblib.load("scaler.pkl")

print("Model and scaler loaded successfully.")

"""# Prepare Sample Input"""

# Take one sample from test set (raw version before scaling if stored)
sample = X_test[0]   # shape (128, 6)

# In real deployment, you would receive raw sensor window here.
sample

sample_reshaped = sample.reshape(-1, 6)
sample_scaled = scaler.transform(sample_reshaped).reshape(1, 128, 6)

"""# Predict"""

prediction = model.predict(sample_scaled)
predicted_class = np.argmax(prediction)

class_map = {
    0: "WALKING",
    1: "WALKING_UPSTAIRS",
    2: "WALKING_DOWNSTAIRS",
    3: "SITTING",
    4: "STANDING",
    5: "LAYING"
}

print("Predicted Activity:", class_map[predicted_class])
print("Confidence:", np.max(prediction))

"""# Plot Sensor Signals (Very Useful for Analysis)"""

plt.figure(figsize=(12,6))
plt.plot(sample[:,0], label="Acc X")
plt.plot(sample[:,1], label="Acc Y")
plt.plot(sample[:,2], label="Acc Z")

plt.title("Accelerometer Signals (128 Timesteps)")
plt.legend()
plt.show()

plt.figure(figsize=(12,6))
plt.plot(sample[:,3], label="Gyro X")
plt.plot(sample[:,4], label="Gyro Y")
plt.plot(sample[:,5], label="Gyro Z")

plt.title("Gyroscope Signals (128 Timesteps)")
plt.legend()
plt.show()